{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pd as pd\n",
    "\n",
    "from traineval.train_eval import TrainerEvaluator\n",
    "from tqdm import tqdm\n",
    "from traineval.utils.convert_arguments import get_environment_arguments\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "from traineval.training.spinningup import data as saved_models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_model_env_arguments(model_type, number_of_epochs, model_seed, save_freq):\n",
    "\n",
    "    # The arguments you want the agent to use\n",
    "    district_args = [\"hour\",\n",
    "                     \"month\",\n",
    "                     \"carbon_intensity\",\n",
    "                     \"electricity_pricing\",\n",
    "                     \"outdoor_dry_bulb_temperature_predicted_6h\",\n",
    "                     \"outdoor_relative_humidity_predicted_6h\"]\n",
    "\n",
    "    building_args = [\"non_shiftable_load\",\n",
    "                     \"solar_generation\",\n",
    "                     \"electrical_storage_soc\",\n",
    "                     \"net_electricity_consumption\"]\n",
    "\n",
    "    environment_arguments = get_environment_arguments(district_args, building_args)\n",
    "\n",
    "    model_args = [\n",
    "        [['--env'], str, 'Epoch-Citylearn-v1'],\n",
    "        [['--hid'], int, 64],\n",
    "        [['--l'], int, 2],\n",
    "        [['--gamma'], float, 0.99],\n",
    "        [['--seed', '-s'], int, model_seed],\n",
    "        [['--cpu'], int, 4],\n",
    "        [['--steps'], int, 4000],\n",
    "        [['--epochs'], int, number_of_epochs],\n",
    "        [['--exp_name'], str, model_type],\n",
    "        [['--save_freq'], int, save_freq],\n",
    "        ]\n",
    "\n",
    "    return model_args, environment_arguments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def get_training_times(model_type, model_seed):\n",
    "    progress_path = model_type + '/' + model_type + '_s' + str(model_seed) + '/progress.txt'\n",
    "    full_path = osp.join(osp.dirname(saved_models.__file__), progress_path)\n",
    "\n",
    "    return list(pd.read_table(full_path))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def get_evaluation_data(trainer_evaluator, model_type, model_seed, num_epochs, eval_freq):\n",
    "\n",
    "    averaged_scores = []\n",
    "    for epoch in tqdm(range(0, num_epochs, eval_freq)):\n",
    "\n",
    "        # TODO: make this run in parallel\n",
    "        averaged_score, agent_time = trainer_evaluator.run_evaluation(model_type=model_type, model_seed=model_seed, model_iteration=str(epoch), verbose=False)\n",
    "        averaged_scores.append(averaged_score)\n",
    "        if epoch + eval_freq >= num_epochs and epoch != num_epochs - 1:\n",
    "            averaged_score, agent_time = trainer_evaluator.run_evaluation(model_type=model_type, model_seed=model_seed, model_iteration=str(epoch), verbose=False)\n",
    "            averaged_scores.append(averaged_score)\n",
    "    return pd.DataFrame({\"averages\":averaged_scores, \"times\": get_training_times(model_type, model_seed)})\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def plot_and_save(title, xs, ys, xlabel, ylabel):\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.plot(xs, ys, marker=\"o\")\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    # ax.plot(gapminder_us.year, gapminder_us[\"gdpPercap\"], marker=\"o\")\n",
    "    plt.savefig(title)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:50<00:00, 25.35s/it]\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 720\n",
    "model_type = \"ppo\"\n",
    "model_args, environment_arguments = create_model_env_arguments(model_type=number_of_epochs, number_of_epochs=model_type, model_seed=0, save_freq=20)\n",
    "\n",
    "trainer_evaluator = TrainerEvaluator(model_args=model_args, environment_arguments=environment_arguments)\n",
    "df_costs_times = get_evaluation_data(trainer_evaluator=trainer_evaluator, model_type=model_type, model_seed=0, num_epochs=number_of_epochs, eval_freq=20)\n",
    "\n",
    "ppo_untuned_title = str.strip(f\"{model_type}-{number_of_epochs}epochs\")\n",
    "plot_and_save(title=ppo_untuned_title, xs=df_costs_times.times, ys=df_costs_times.averages, xlabel=\"Time spent (s)\", ylabel=\"Average cost\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "number_of_epochs = 1240\n",
    "model_type = \"ppo\"\n",
    "model_args, environment_arguments = create_model_env_arguments(model_type=model_type, number_of_epochs=1240, model_seed=0, save_freq=20)\n",
    "\n",
    "trainer_evaluator = TrainerEvaluator(model_args=model_args, environment_arguments=environment_arguments)\n",
    "df_costs_times = get_evaluation_data(trainer_evaluator=trainer_evaluator, model_type=model_type, model_seed=0, num_epochs=number_of_epochs, eval_freq=20)\n",
    "\n",
    "ppo_untuned_title = str.strip(f\"{model_type}-{number_of_epochs}epochs\")\n",
    "plot_and_save(title=ppo_untuned_title, xs=df_costs_times.times, ys=df_costs_times.averages, xlabel=\"Time spent training (s)\", ylabel=\"Average cost\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}