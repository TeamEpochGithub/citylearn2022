{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CityLearn MARLISA 2022\n",
    "\n",
    "```\n",
    "Author: Chia E Tungom\n",
    "Email: bamtungom@protonmail.com\n",
    "Date: Aug-11-2022\n",
    "```\n",
    "\n",
    "In this Notebook we outline how the Multiagent Reinforcement Learning Algorithm MARLISA can be modified for the 2022 CityLearn Challenge.\n",
    "For details on how MARLISA works, refer to the [study]() and for the orignal implementation refer to the [CityLearn git repository](https://github.com/intelligent-environments-lab/CityLearn/blob/master/agents/marlisa.py).\n",
    "\n",
    "A brief of what the algorithm aims to achieve is a follows \n",
    "1. Implement a Multi-agent version of Soft-Actor Critic (SAC) algorithm\n",
    "    - Design a reward function with individual and collective goals\n",
    "    - Agents share information amongs each other using a leader-follower scheme\n",
    "        - Each building has it's own RL agent\n",
    "2. Use the algorithm to\n",
    "    - Plan and Control energy storage of a diverse set of buildings\n",
    "    - Aim to reshape the aggregated curve of electricity demand\n",
    "    - Decide how much heating and cooling is stored or released at any time\n",
    "3. Measure performance on the following metric\n",
    "    - Annual net electricity consumption in the district\n",
    "    - Average daily peak demand\n",
    "    - Annual peak demand \n",
    "    - Ramping \n",
    "\n",
    "Unlike the CityLearn environment where MARLISA was implemented in, the 2022 CityLearn Challenge environment has different environmnet features and optimization objective. \n",
    "In this Notebook we aim to show how MARLISA can be adapted to the 2022 CityLearn Challenge. We do so by doing the following \n",
    "1. Setting Up the CityLearn 2022 Environment\n",
    "2. Getting Building information (should be MARLISA compatible)\n",
    "3. Some Data Overview\n",
    "4. Generate Building State Actions requirements\n",
    "5. Outline Modifications of MARLISA code\n",
    "6. Run `MARLISA2022`\n",
    "\n",
    "__Note:__ I only aim to make it easier for those who want to get started with MARL(ISA)\n",
    "\n",
    "To Run this Notebook, you will need to have the started git repo with the following folder\n",
    "- Get the MARLISA python file from the [intelligent-environments-lab](https://github.com/intelligent-environments-lab/CityLearn/blob/master/agents/marlisa.py) git hub repo and place in the agents folder \n",
    "- Get the common folder from the [intelligent-environments-lab](https://github.com/intelligent-environments-lab/CityLearn/tree/master/common) and place in the root folder of ur starter git folder\n",
    "- Place this Notebook in the root folder as well\n",
    "- __YOU ARE GOOD TO GO !!!!__\n",
    "\n",
    "__This Notebook was made while listening to [MONALISA](https://www.youtube.com/watch?v=to8nQNGarRw). Enjoy!!! __\n",
    "\n",
    "__Lets Gooooooooooo!!!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Load Environment \n",
    "\n",
    "We beginning by setting Up our RL environment for CityLearn2022. Some of the code in this section  was  taken from the local evaluation python file in the starter kit repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "# from citylearn import CityLearn\n",
    "# !pip3 install sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from agents.marlisa import MARLISA\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "\n",
    "# Custom configure enviroment \n",
    "class Constants:\n",
    "    episodes = 3\n",
    "    schema_path = './data/citylearn_challenge_2022_phase_1/schema.json'\n",
    "\n",
    "def action_space_to_dict(aspace):\n",
    "    \"\"\" Only for box space \"\"\"\n",
    "    return { \"high\": aspace.high,\n",
    "             \"low\": aspace.low,\n",
    "             \"shape\": aspace.shape,\n",
    "             \"dtype\": str(aspace.dtype)\n",
    "    }\n",
    "\n",
    "def env_reset(env):\n",
    "    observations = env.reset()\n",
    "    action_space = env.action_space\n",
    "    observation_space = env.observation_space\n",
    "    building_info = env.get_building_information()\n",
    "    building_info = list(building_info.values())\n",
    "    action_space_dicts = [action_space_to_dict(asp) for asp in action_space]\n",
    "    observation_space_dicts = [action_space_to_dict(osp) for osp in observation_space]\n",
    "    obs_dict = {\"action_space\": action_space_dicts,\n",
    "                \"observation_space\": observation_space_dicts,\n",
    "                \"building_info\": building_info,\n",
    "                \"observation\": observations }\n",
    "    return obs_dict\n",
    "\n",
    "env = CityLearnEnv(schema=Constants.schema_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Get Building Information\n",
    "\n",
    "Building Information is needed as input in the MARLISA algorithm. Building information contains information like \n",
    "- A buildings solar power storage capacity\n",
    "- A buildings annual demand for cooling, heating  and dhw (deep hot water)\n",
    "- And other information\n",
    "\n",
    "To get building information, you can run the command `env.get_building_information()`. The information we get does not contain keys like Building_1 which as needed but rather some sequence of random letters and numbers. We make modifications to rename the buildings in the order they appear (I am not sure this renaming is proper and if you have an idea please leave a comment below).\n",
    "\n",
    "The Buildings are renamed the same way buildings are named in the CityLearn environment."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observations_spaces, actions_spaces = env.observation_space, env.action_space\n",
    "\n",
    "building_info = env.get_building_information()\n",
    "\n",
    "def RenameBuilding(Building_Info):\n",
    "    newB = {}\n",
    "    for i, building in enumerate(Building_Info):\n",
    "        newB[\"Building_\"+str(i+1)] = building_info[building]\n",
    "    return newB\n",
    "\n",
    "building_info = RenameBuilding(building_info)\n",
    "building_info['Building_1']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. A Look at Building Data\n",
    "\n",
    "Taking a Look at Building Data we see that the observations\n",
    "\n",
    "- `Indoor Temperature [C]`, `Average Unmet Cooling Setpoint Difference [C]` and `Indoor Relative Humidity [%]`: All have NaN values \t\n",
    "- `DHW Heating [kWh]`, `Cooling Load [kWh]` and `Heating Load [kWh]`: \tAll have values 0\n",
    "\n",
    "If this is the case when sampled in the environmet, we don't need this variables for learning a model as they don't provide any information about a building  or state.\n",
    "\n",
    "This is useful because inside MARLISA we can set which observations to be removed if need be"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "data = pd.read_csv('data/citylearn_challenge_2022_phase_1/Building_1.csv')\n",
    "Missing = data.isnull().sum()\n",
    "\n",
    "long_df = px.data.medals_long()\n",
    " \n",
    "fig = px.bar(x = Missing.index, y = Missing.values,\n",
    "             color = Missing.index, title = \"Count of Missing Data\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Generate Building States  Action Requirements \n",
    "\n",
    "This is an input to the MARLISA algorithm and is used to determine which states or actions are needed for each building. Unlike in the 2020 MARLISA where a buildings requirements file is nicely provided, the information in the 2022 challenge is in the schema.json file. The Requirements for each building state and action is provided (I assume it is same for all buildings) but we need to  modify it for our inpute to suit the algorithm. \n",
    "\n",
    "In the file a state with value True means it's required  for the given building and an action with value True means that action needs to be taken for that building and False otherwise.\n",
    "\n",
    "We see that only action `electrial storage` is needed.\n",
    "\n",
    "__NOTE: The order  of  the states is same as the order of the observations i.e if month is first then in observation it's in index 0. e.g Hour comes third which mean it's found in index 2__: \n",
    "\n",
    "After generating the file, you can save it in Json format for usage as input or give to your algorithm in the dictionary format. Here we use the latter. If you use the latter, comment `line [37-38]` where the file is read in."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def GenStateActionFromJson(JsonPath, BuildingCount = 5):\n",
    "\n",
    "    with open(JsonPath) as json_file:\n",
    "        buildings_states_actions = json.load(json_file)\n",
    "\n",
    "    States = buildings_states_actions['observations']\n",
    "    Actions = buildings_states_actions['actions']\n",
    "\n",
    "    StateINFo = {}\n",
    "    ActionINFo = {}\n",
    "    INFos = {}\n",
    "    \n",
    "    for var, ins in States.items():\n",
    "        #print(var, \" <><> \", ins)\n",
    "        if ins['active']:\n",
    "            StateINFo[var] = ins['active']\n",
    "    for act, ins  in Actions.items():\n",
    "        if ins['active']:\n",
    "            ActionINFo[act] = ins['active']\n",
    "\n",
    "    INFos[\"states\"] = StateINFo\n",
    "    INFos[\"action\"] = ActionINFo\n",
    "\n",
    "    return {\"Building_\" + str(key): INFos for key in range(1,BuildingCount+1)}\n",
    "\n",
    "\n",
    "JsonFile = 'data/citylearn_challenge_2022_phase_1/schema.json'\n",
    "BuildingsStatesActions = GenStateActionFromJson(JsonFile, BuildingCount = 5)\n",
    "\n",
    "BuildingsStatesActions[\"Building_1\"][\"states\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Internal MARLISA Modification\n",
    "\n",
    "MARLISA CODE Tips for modification for 2022 challenge\n",
    "\n",
    "### 5.1. Initialization (__init__ body) \n",
    "\n",
    "`[Line 58 to 65]` abstract information to individual buildings\n",
    "\n",
    "`[Line 75-83]` Energy size coefficient for every building (Not Needed in 2022)\n",
    "\n",
    "`[Line 86-111]` __Define Encoder__: Set Regression Learner for every building, define Encoding for every observation (think of it as data column) and set target variable to be removed __MODIFY ACCORDING TO THE CURRENT DATASET__\n",
    "\n",
    "`[Line 131-145]` __Define Regression Encoder__: for transforming states in regression model __MODIFY ACCORDING TO THE CURRENT DATASET__\n",
    "\n",
    "`[Line 149-164]` __Solar Capacity (remove variables if no solar PV)__: removes solar radiation related variables for houses without PV __COMMENT THIS SECTION__\n",
    "\n",
    "\n",
    "### 5.2. Select Action (MARLISA method or function)\n",
    "\n",
    "- Takes as inputs `states` and `deterministic`\n",
    "    - `states`: the states of the buildings\n",
    "    - `deterministic`: boolean can be true or false\n",
    "\n",
    "`**[Line 222-226]` __Initialize coordination variables__: coordination variables are two dimesional for every building. __MODIFY ACCORDING TO THE CURRENT DATASET (in 2022 we are asked to optimize for electricty cost and carbon emission)__\n",
    "- `Capacity  Dispatched:` This is the total amount of electricity already dispatched. it is related to the energy size coefficient at every time step\n",
    "- `**Electrical Demand`: Related to the total electricity demand estimated by a prediction algorithm. __Different in Information Sharing and Non Info Sharing Cases__\n",
    "\n",
    "\n",
    "AFTER the recommended modifications you can make a trial run as shown next\n",
    "\n",
    "The __REWARD FUNCTION can also be modified__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. RUN MARLISA 2022\n",
    "\n",
    "To run Marlisa, we need to give it parameters that influence it's learning \n",
    "\n",
    "The MARLISA Algorithm takes inputs that we can be classified into two categories\n",
    "\n",
    "### 6.1. Environment Parameters\n",
    "\n",
    "These are parameters specific to the reinforcement learning environment (CityLearn Version). They give information about the simulation environment that will be used. details about these environmental variables are explored above, to understanding the [2022 citylearn environment, check this notebook](https://www.aicrowd.com/showcase/baby-steps-5fd2bef3-19a6-4ba6-887a-6bbe957a4e33). A summary explanation can be laid down as follows.\n",
    "\n",
    "- __'building_ids':__ These are the buildings identities in the environment written in the form `\"Building_id\"` where id is a building number a building_id can look as follows\n",
    "    - `[\"Building_1\", \"Building_2\", ... , \"Building_n\"]`\n",
    "- __'buildings_states_actions':__ This is a json file defining the different states and actions possible for a building e.g If a building has a \n",
    "    - `states {day :  False,  temp: True}` it means there will be information for temp but not for day\n",
    "    - `\"actions\": {\"cooling_storage\": true, \"dhw_storage\": true, \"electrical_storage\": false}`. this means there will be no action required or electric storage is absent in the building\n",
    "- __'building_info':__ Gives valuable information about a building like\n",
    "    - `solar_power_capacity (kW)`\n",
    "    - `Annual_DHW_demand (kWh)`\n",
    "    - `Annual_cooling_demand (kWh)`\n",
    "    - `Annual_nonshiftable_electrical_demand (kWh)`\n",
    "    - `etc`\n",
    "- __'observation_spaces':__ This is information about the observation space of every building in the environment. \n",
    "    - It contains n arrays where n is the number of buildings\n",
    "    - Each array contains the lower and upper bound for the building observation along with it's dimension and datatype\n",
    "- __'action_spaces':__ This is information about the actions_spaces of every building in the environment\n",
    "    - It contains n arrays where n is the number of buildings\n",
    "    - Each array contains the lower and upper bound for the building action along with it's dimension and datatype\n",
    "\n",
    "\n",
    "### 6.2. Algorithm Parameters\n",
    "\n",
    "These are parameters specific to our reinforcement learning algorithm. Details about these parameters can be found in the [paper](https://dl.acm.org/doi/10.1145/3408308.3427604). The settings below  are as provided in the original MARLISA implementation found [here](https://github.com/intelligent-environments-lab/CityLearn/blob/master/examples/example_marlisa.ipynb)\n",
    "\n",
    "- `hidden_dim`:[256,256], \n",
    "- `discount`:0.99, \n",
    "- `tau`:5e-3, \n",
    "- `lr`:3e-4, \n",
    "- `batch_size`:256, \n",
    "- `replay_buffer_capacity`:1e5, \n",
    "- `regression_buffer_capacity`:3e4, \n",
    "- `start_training`:600, # Start updating actor-critic networks\n",
    "- `exploration_period`:7500, # Just taking random actions\n",
    "- `start_regression`:500, # Start training the regression model\n",
    "- `information_sharing`:True, # If True -> set the appropriate 'reward_function_ma' in reward_function.py\n",
    "- `pca_compression`:.95, \n",
    "- `action_scaling_coef`:0.5, # Actions are multiplied by this factor to prevent too aggressive actions\n",
    "- `reward_scaling`:5., # Rewards are normalized and multiplied by this factor\n",
    "- `update_per_step`:2, # How many times the actor-critic networks are updated every hourly time-step\n",
    "- `iterations_as`:2,# Iterations of the iterative action selection (see MARLISA paper for more info)\n",
    "- `safe_exploration`:True\n",
    "\n",
    "__NOTE: Set the appropriate number of buildings as the environment. Ensure the BuildingsStatesActions generated have same number of buildings as the given environment__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params_agent = {'building_ids':[\"Building_\"+str(i) for i in [1,2,3,4,5]],\n",
    "                 'buildings_states_actions':BuildingsStatesActions, \n",
    "                 'building_info':building_info,\n",
    "                 'observation_spaces':observations_spaces, \n",
    "                 'action_spaces':actions_spaces, \n",
    "                 'hidden_dim':[256,256], \n",
    "                 'discount':1/12, \n",
    "                 'tau':5e-3, \n",
    "                 'lr':3e-4, \n",
    "                 'batch_size':256, \n",
    "                 'replay_buffer_capacity':1e5, \n",
    "                 'regression_buffer_capacity':3e4, \n",
    "                 'start_training':600, # Start updating actor-critic networks\n",
    "                 'exploration_period':7500, # Just taking random actions\n",
    "                 'start_regression':500, # Start training the regression model\n",
    "                 'information_sharing':True, # If True -> set the appropriate 'reward_function_ma' in reward_function.py\n",
    "                 'pca_compression':.95, \n",
    "                 'action_scaling_coef':0.5, # Actions are multiplied by this factor to prevent too aggressive actions\n",
    "                 'reward_scaling':5., # Rewards are normalized and multiplied by this factor\n",
    "                 'update_per_step':2, # How many times the actor-critic networks are updated every hourly time-step\n",
    "                 'iterations_as':2,# Iterations of the iterative action selection (see MARLISA paper for more info)\n",
    "                 'safe_exploration':True} \n",
    "\n",
    "# Instantiating the control agent(s)\n",
    "agents = MARLISA(**params_agent)\n",
    "\n",
    "RUNTIME = 30*24\n",
    "shortcut = True\n",
    "cutshort = True\n",
    "# We will use 1 episode if we intend to simulate a real-time RL controller (like in the CityLearn Challenge)\n",
    "# In climate zone 5, 1 episode contains 5 years of data, or 8760*5 time-steps.\n",
    "n_episodes = 1\n",
    "start = time.time()\n",
    "for e in tqdm(range(n_episodes)): \n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    j = 0\n",
    "    is_evaluating = False\n",
    "    action, coordination_vars = agents.select_action(state, deterministic=is_evaluating)\n",
    "\n",
    "    while (not done) and shortcut:\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        action_next, coordination_vars_next = agents.select_action(next_state, deterministic=is_evaluating)\n",
    "        agents.add_to_buffer(state, action, reward, next_state, done, coordination_vars, coordination_vars_next)\n",
    "        coordination_vars = coordination_vars_next\n",
    "        state = next_state\n",
    "        action = action_next\n",
    "\n",
    "        if j%(24*30) == 0:\n",
    "            print(f' We are now in step <><><> {j}, with score >> {env.evaluate()}')\n",
    "        # if cutshort:\n",
    "        #     is_evaluating = (j > (3*RUNTIME)/2)\n",
    "        #     j += 1\n",
    "        \n",
    "        is_evaluating = (j > 3*8760)\n",
    "        j += 1\n",
    "        \n",
    "        # if j >= RUNTIME:\n",
    "        #     shortcut = False\n",
    "        \n",
    "    print('Loss -',env.evaluate(), 'Simulation time (min) -',(time.time()-start)/60.0)\n",
    "    # CPU training for 603mins "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### HOPE U LIKED THE SONG\n",
    "\n",
    "Leave a comment for any questions, doubts or corrections"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15c682508d24c5a67d5fbbe2fea073172b3a3ca9fabad277d65ba1c57669360a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('CityLearn2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}